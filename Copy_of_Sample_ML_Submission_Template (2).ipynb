{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Classification/Unsupervised\n",
        "##### **Contribution**    - Individual/Team\n",
        "##### **Name**            - Amit Kumar\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Summary: Diabetes Classification Using Machine Learning\n",
        "Diabetes classification involves predicting whether an individual has diabetes based on various medical attributes. This process is vital for early diagnosis and management, ultimately helping in reducing the health risks associated with diabetes. The classification model utilizes attributes such as pregnancies, glucose levels, blood pressure, skin thickness, insulin levels, BMI, diabetes pedigree function, age, and the outcome (presence or absence of diabetes).\n",
        "\n",
        "Data Preparation\n",
        "The first step in building a diabetes classification model is data preparation. This involves loading the dataset, handling missing values, and normalizing or standardizing the data if necessary. Missing values can significantly affect the performance of the model, so they are typically handled by replacing them with the mean or median values of the respective attributes.\n",
        "\n",
        "Exploratory Data Analysis (EDA)\n",
        "EDA helps in understanding the data better. It involves analyzing the distribution of each attribute, visualizing relationships between attributes, and checking for class imbalances in the outcome variable. Visual tools such as histograms, box plots, and correlation matrices are often used to gain insights into the data and its characteristics.\n",
        "\n",
        "Feature Engineering\n",
        "Feature engineering involves creating new features or selecting important features that contribute most to the predictive power of the model. This step is crucial as it can enhance the performance of the model by providing more relevant information to the algorithms.\n",
        "\n",
        "Model Selection\n",
        "Several classification algorithms can be employed for diabetes prediction, including Logistic Regression, Decision Tree, Random Forest, Support Vector Machine (SVM), and K-Nearest Neighbors (KNN). The choice of model depends on the specific characteristics of the dataset and the problem at hand. The data is typically split into training and testing sets to evaluate the performance of the models.\n",
        "\n",
        "Model Training\n",
        "Models are trained on the training dataset. Hyperparameter tuning is performed using cross-validation to find the best set of parameters that improve the model's performance. For instance, Logistic Regression and Random Forest are popular choices due to their simplicity and effectiveness.\n",
        "\n",
        "Model Evaluation\n",
        "The trained models are evaluated on the testing dataset using various metrics such as accuracy, precision, recall, F1-score, and ROC-AUC. These metrics provide insights into the model's performance and help in comparing different models. For instance, confusion matrices and classification reports can highlight the number of true positives, false positives, true negatives, and false negatives, offering a detailed evaluation of the model's predictions.\n",
        "\n",
        "Model Deployment\n",
        "After evaluating the models, the best-performing model is selected for deployment. This model is then used to make predictions on new data. In practice, a model with higher accuracy and better evaluation metrics is preferred for deployment."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diabetes is a chronic medical condition that affects millions of people worldwide, leading to severe health complications if not managed properly. Early diagnosis and timely intervention are crucial in mitigating the risks associated with diabetes. The objective of this project is to develop a predictive machine learning model that can accurately classify individuals as diabetic or non-diabetic based on a set of medical attributes."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df=pd.read_csv('https://raw.githubusercontent.com/sahiamit1993/Diabetes-Prediction/main/diabetes-vid.csv')\n",
        "df"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "srV_M1g-I4B0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "def dataset_info(data):\n",
        "    print('*'*30,'About the dataset :','*'*20)\n",
        "    print()\n",
        "    print()\n",
        "    print('Number of rows :',data.shape[0])\n",
        "    print('Number of columns :',data.shape[1])\n",
        "    print()\n",
        "    print('*'*80)\n",
        "    print(data.info())\n",
        "    print()\n",
        "    print('*'*80)\n",
        "    print('Missing values :')\n",
        "    print()\n",
        "    print(data.isna().sum())\n",
        "    print()\n",
        "    print('*'*80)\n",
        "    print('NUmber of duplicates :',data.duplicated().sum())\n",
        "    print()\n",
        "    print('*'*80)\n",
        "    print('variables =',[i for i in df.columns])\n",
        "    print()\n",
        "    print('*'*80)\n",
        "    print('Target variable : ')\n",
        "    print(data['Outcome'].value_counts())"
      ],
      "metadata": {
        "id": "j71X4AA5I-NZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_info(df)"
      ],
      "metadata": {
        "id": "Ni1q5zkcJeU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "-np5wcHUJ5cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isna())"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 768 rows and 9 columns.\n",
        "There are no missing or null values in the dataset.\n",
        "There are no duplicate values in the dataset.\n",
        "The target variable is 'Outcome', which indicates whether a person has diabetes (1) or not (0).\n",
        "The dataset is imbalanced, with more instances of non-diabetic individuals than diabetic individuals."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "kWkU4tk2LQ7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pregnancies: This attribute indicates the number of times the patient has been pregnant. This can be relevant as pregnancy can influence glucose levels and insulin sensitivity.\n",
        "\n",
        "Glucose: This represents the plasma glucose concentration measured 2 hours after an oral glucose tolerance test. Higher glucose levels are indicative of poor blood sugar control and can be a sign of diabetes.\n",
        "\n",
        "Blood Pressure: This is the diastolic blood pressure (measured in mm Hg). High blood pressure is often associated with diabetes and other cardiovascular conditions.\n",
        "\n",
        "Skin Thickness: The triceps skinfold thickness measured in millimeters. It is used to estimate the amount of subcutaneous fat and can be related to obesity, which is a risk factor for diabetes.\n",
        "\n",
        "Insulin: The 2-hour serum insulin (measured in mu U/ml). Insulin levels can help in assessing insulin resistance, a common feature in Type 2 diabetes.\n",
        "\n",
        "BMI (Body Mass Index): This is calculated as weight in kilograms divided by height in meters squared (kg/m^2). BMI is a measure of body fat based on height and weight. Higher BMI values are linked to a higher risk of developing diabetes.\n",
        "\n",
        "Diabetes Pedigree Function: This is a function that scores the likelihood of diabetes based on family history. It combines information from multiple family members and their medical history to estimate the genetic predisposition to diabetes.\n",
        "\n",
        "Age: The age of the patient (in years). The risk of diabetes increases with age, making this an important factor in predicting the disease.\n",
        "\n",
        "Outcome: This is the target variable and is binary. It indicates whether the individual has diabetes (1) or does not have diabetes (0)."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#no missing values"
      ],
      "metadata": {
        "id": "vjz9MIH-Mzeb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "#checking for outliers\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.boxplot(data=df)\n",
        "plt.show()\n",
        "#treating outliers\n",
        "#removing outliers from 'Insulin' column\n",
        "Q1=df['Insulin'].quantile(0.25)\n",
        "Q3=df['Insulin'].quantile(0.75)\n",
        "IQR=Q3-Q1\n",
        "lower_limit=Q1-1.5*IQR\n",
        "upper_limit=Q3+1.5*IQR\n",
        "df=df[(df['Insulin']>lower_limit) & (df['Insulin']<upper_limit)]\n",
        "#removing outliers from 'Pregnancies' column\n",
        "Q1=df['Pregnancies'].quantile(0.25)\n",
        "Q3=df['Pregnancies'].quantile(0.75)\n",
        "IQR=Q3-Q1\n",
        "lower_limit=Q1-1.5*IQR\n",
        "upper_limit=Q3+1.5*IQR\n",
        "df=df[(df['Pregnancies']>lower_limit) & (df['Pregnancies']<upper_limit)]\n",
        "#removing outliers from 'SkinThickness' column\n",
        "Q1=df['SkinThickness'].quantile(0.25)\n",
        "Q3=df['SkinThickness'].quantile(0.75)\n",
        "IQR=Q3-Q1\n",
        "lower_limit=Q1-1.5*IQR\n",
        "upper_limit=Q3+1.5*IQR\n",
        "df=df[(df['SkinThickness']>lower_limit) & (df['SkinThickness']<upper_limit)]\n",
        "#removing outliers from 'BloodPressure' column\n",
        "Q1=df['BloodPressure'].quantile(0.25)\n",
        "Q3=df['BloodPressure'].quantile(0.75)\n",
        "IQR=Q3-Q1\n",
        "lower_limit=Q1-1.5*IQR\n",
        "upper_limit=Q3+1.5*IQR\n",
        "df=df[(df['BloodPressure']>lower_limit) & (df['BloodPressure']<upper_limit)]\n",
        "#removing outliers from 'BMI' column\n",
        "Q1=df['BMI'].quantile(0.25)\n",
        "Q3=df['BMI'].quantile(0.75)\n",
        "IQR=Q3-Q1\n",
        "lower_limit=Q1-1.5*IQR\n",
        "upper_limit=Q3+1.5*IQR\n",
        "df=df[(df['BMI']>lower_limit) & (df['BMI']<upper_limit)]\n",
        "#removing outliers from 'DiabetesPedigreeFunction' column\n",
        "Q1=df['DiabetesPedigreeFunction'].quantile(0.25)\n",
        "Q3=df['DiabetesPedigreeFunction'].quantile(0.75)\n",
        "IQR=Q3-Q1\n",
        "lower_limit=Q1-1.5*IQR\n",
        "upper_limit=Q3+1.5*IQR\n",
        "df=df[(df['DiabetesPedigreeFunction']>lower_limit) & (df['DiabetesPedigreeFunction']<upper_limit)]\n",
        "#removing outliers from 'Age' column\n",
        "Q1=df['Age'].quantile(0.25)\n",
        "Q3=df['Age'].quantile(0.75)\n",
        "IQR=Q3-Q1\n",
        "lower_limit=Q1-1.5*IQR\n",
        "upper_limit=Q3+1.5*IQR\n",
        "df=df[(df['Age']>lower_limit) & (df['Age']<upper_limit)]\n",
        "#checking for outliers\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.boxplot(data=df)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Mj4gjVMNNOME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I used the IQR method to remove outliers. This method is effective in identifying and removing outliers that are significantly different from the rest of the data.\n",
        " The IQR method is also relatively simple to implement and understand.\n",
        "\n",
        " Here are the steps involved in the IQR method:\n",
        "\n",
        " 1. Calculate the first quartile (Q1) and third quartile (Q3) of the data.\n",
        " 2. Calculate the interquartile range (IQR) as Q3 - Q1.\n",
        " 3. Define the lower and upper bounds as Q1 - 1.5 * IQR and Q3 + 1.5 * IQR, respectively.\n",
        " 4. Remove any data points that fall outside of these bounds.\n",
        "\n",
        " I used this method because it is a common and effective way to remove outliers. It is also relatively simple to implement and understand.\n",
        " In this particular case, the IQR method was effective in removing outliers from the data.\n",
        " This can be seen in the box plot after the outlier treatment, which shows that there are no longer any data points that fall outside of the whiskers."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "variables = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
        "num_col = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
        "cat_col = ['Outcome']"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(4, 2, figsize=(10, 10))\n",
        "\n",
        "n = 0\n",
        "\n",
        "for i in num_col:\n",
        "    sns.histplot(data=df, x=i, kde=True, ax=ax[n//2, n%2])\n",
        "\n",
        "    ax[n//2, n%2].set_title(f'Histogram of {i}')\n",
        "\n",
        "    n += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M_LAy4h1N1Ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(4, 2, figsize=(10, 10))\n",
        "\n",
        "n = 0\n",
        "\n",
        "for i in num_col:\n",
        "    sns.boxplot(data=df, x='Outcome',y=i, ax=ax[n//2, n%2])\n",
        "\n",
        "    ax[n//2, n%2].set_title(f'Boxplot of {i}')\n",
        "\n",
        "    n += 1\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KpTEg5trN8DS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df,x='Outcome')\n",
        "plt.title('Box plot of Outcome variable')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Msj9_pPqOAAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Outcome',axis=1)\n",
        "y = df['Outcome']"
      ],
      "metadata": {
        "id": "gwBfUCgSOGka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE()\n",
        "X_resampled,y_resampled=smote.fit_resample(X,y,)"
      ],
      "metadata": {
        "id": "Nl35YATbOIUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std = StandardScaler()"
      ],
      "metadata": {
        "id": "FLiLiPA1ONBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "X_train,X_test,y_train,y_test = train_test_split(std.fit_transform(X_resampled),y_resampled,test_size=0.2,random_state=123)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_JgMZaU3OVGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression()\n",
        "dt = DecisionTreeClassifier()\n",
        "rf = RandomForestClassifier()\n",
        "svc = SVC()"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_info(model):\n",
        "    print()\n",
        "    print(f'For {model}')\n",
        "    print()\n",
        "    model.fit(X_train,y_train)\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    cla_repo_train = classification_report(y_train,y_pred_train)\n",
        "    conf_mat_train = confusion_matrix(y_train,y_pred_train)\n",
        "\n",
        "    cla_repo_test = classification_report(y_test,y_pred_test)\n",
        "    conf_mat_test = confusion_matrix(y_test,y_pred_test)\n",
        "\n",
        "    print('Classification report (Train):')\n",
        "    print()\n",
        "    print(cla_repo_train)\n",
        "    print()\n",
        "    print('Classification report (Test):')\n",
        "    print()\n",
        "    print(cla_repo_test)\n",
        "    print()\n",
        "    print('*'*80)\n",
        "    print('Confusion metrix (Train):')\n",
        "    print()\n",
        "    print(conf_mat_train)\n",
        "    print()\n",
        "    print('Confusion metrix (Test):')\n",
        "    print()\n",
        "    print(conf_mat_test)\n",
        "    print()\n",
        "    print('*'*80)\n",
        "    print('*'*80)\n",
        "    print('*'*80)"
      ],
      "metadata": {
        "id": "3q06guE_Og5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [lr,dt,rf,svc]\n",
        "\n",
        "for model in models:\n",
        "    model_info(model)"
      ],
      "metadata": {
        "id": "Dz5em6fOOj-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression:\n",
        "- Achieved an accuracy of 78% on the training set and 77% on the testing set.\n",
        "- Shows a good balance between precision and recall for both classes.\n",
        "\n",
        "Decision Tree Classifier:\n",
        "- Achieved perfect accuracy (100%) on the training set, indicating potential overfitting.\n",
        "- Performance on the testing set is lower (73%), suggesting overfitting to the training data.\n",
        "\n",
        "Random Forest Classifier:\n",
        "- Achieved an accuracy of 100% on the training set, also indicating potential overfitting.\n",
        "- Performed better on the testing set (81%) compared to Decision Tree, suggesting better generalization.\n",
        "\n",
        "Support Vector Classifier (SVC):\n",
        "- Achieved an accuracy of 81% on the training set and 79% on the testing set.\n",
        "- Shows a good balance between precision and recall for both classes.\n",
        "\n",
        "Overall:\n",
        "- Random Forest Classifier shows the best performance on the testing set, indicating its ability to generalize well.\n",
        "- Decision Tree Classifier shows signs of overfitting, which needs to be addressed through techniques like pruning or limiting tree depth.\n",
        "- Logistic Regression and SVC provide decent performance with a good balance between precision and recall.\n",
        "\n",
        "Further steps could include:\n",
        "- Hyperparameter tuning for all models to optimize their performance.\n",
        "- Exploring other classification algorithms like K-Nearest Neighbors or Gradient Boosting.\n",
        "- Addressing the class imbalance in the dataset using techniques like oversampling or undersampling."
      ],
      "metadata": {
        "id": "NXmOH7_KO8Ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(data=df,x='Outcome')\n",
        "plt.title('Count plot of Outcome variable')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Melt5UyFPL92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we tackled the challenge of diabetes classification using machine learning techniques.\n",
        "We explored various algorithms, including Logistic Regression, Decision Tree, Random Forest, and Support Vector Machine (SVM),\n",
        "to predict whether an individual has diabetes based on medical attributes.\n",
        "\n",
        "Through rigorous data preprocessing, exploratory data analysis, and model evaluation,\n",
        "we identified the most effective model for this specific dataset.\n",
        "\n",
        "The chosen model demonstrated promising results in terms of accuracy, precision, recall, and F1-score,\n",
        "indicating its potential for real-world application in assisting healthcare professionals with early diabetes diagnosis.\n",
        "\n",
        "However, it's important to acknowledge that no model is perfect, and further improvements can be explored.\n",
        "Future work could involve:\n",
        "\n",
        "- Experimenting with additional algorithms or ensemble methods to potentially enhance predictive performance.\n",
        "- Incorporating more diverse and comprehensive datasets to improve the model's generalizability.\n",
        "- Fine-tuning hyperparameters and exploring advanced feature engineering techniques to optimize the model's accuracy.\n",
        "\n",
        "Overall, this project highlights the significant role machine learning can play in addressing critical healthcare challenges like diabetes prediction,\n",
        "paving the way for more effective and timely interventions."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}